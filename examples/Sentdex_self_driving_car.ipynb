{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5633c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "import math\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "import tensorflow.compat.v1.keras.backend as backend\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from threading import Thread\n",
    "\n",
    "from collections import deque \n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "try:\n",
    "    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "\n",
    "import carla\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ac46b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_PREVIEW = True\n",
    "IM_WIDTH = 640\n",
    "IM_HEIGHT = 480\n",
    "SECONDS_PER_EPISODE = 30\n",
    "REPLAY_MEMORY_SIZE = 5_000\n",
    "MIN_REPLAY_MEMORY_SIZE = 1_000\n",
    "MINIBATCH_SIZE = 16\n",
    "PREDICTION_BATCH_SIZE = 1\n",
    "TRAINING_BATCH_SIZE = MINIBATCH_SIZE//4\n",
    "UPDATE_TARGET_EVERY = 20\n",
    "MODEL_NAME = \"Xception\"\n",
    "\n",
    "MEMORY_FRACTION = 0.8\n",
    "MIN_REWARD = -200\n",
    "\n",
    "EPISODES = 5\n",
    "\n",
    "DISCOUNT = 0.99\n",
    "epsilon = 1\n",
    "EPSILON_DECAY = 0.95 ## 0.9975 99975\n",
    "MIN_EPSILON = 0.001\n",
    "\n",
    "AGGREGATE_STATS_EVERY = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "846eaba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarEnv:\n",
    "    \n",
    "    \n",
    "    SHOW_CAM = SHOW_PREVIEW\n",
    "    STEER_AMT = 0.8\n",
    "    \n",
    "    im_width = IM_WIDTH\n",
    "    im_height = IM_HEIGHT\n",
    "    \n",
    "    rgb_image = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = carla.Client(\"localhost\", 2000)\n",
    "        self.client.set_timeout(5.0)\n",
    "        \n",
    "        self.world = self.client.get_world()\n",
    "        self.world_map = self.world.get_map()\n",
    "        \n",
    "        self.blueprint_library = self.world.get_blueprint_library()\n",
    "        \n",
    "        self.model_3_bp = self.blueprint_library.filter(\"model3\")[0]\n",
    "        \n",
    "    def reset(self):\n",
    "        self.collision_hist = []\n",
    "        self.actor_list = []\n",
    "        \n",
    "        self.transform = random.choice(self.world_map.get_spawn_points())\n",
    "        self.vehicle = self.world.spawn_actor(self.model_3_bp, self.transform)\n",
    "        self.actor_list.append(self.vehicle)\n",
    "        \n",
    "        self.spectator = self.world.get_spectator() \n",
    "        self.spectator.set_transform(self.vehicle.get_transform())\n",
    "        \n",
    "        self.rgb_cam_bp = self.blueprint_library.find(\"sensor.camera.rgb\")\n",
    "        \n",
    "        self.rgb_cam_bp.set_attribute('image_size_x', str(self.im_width))\n",
    "        self.rgb_cam_bp.set_attribute('image_size_y', str(self.im_height))\n",
    "        self.rgb_cam_bp.set_attribute('fov', str(110))\n",
    "        \n",
    "        transform = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "        self.rgb_cam_sensor = self.world.spawn_actor(self.rgb_cam_bp, transform, attach_to=self.vehicle)\n",
    "        self.actor_list.append(self.rgb_cam_sensor)\n",
    "        \n",
    "        self.rgb_cam_sensor.listen(lambda data: self.process_img(data))\n",
    "        \n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=0.0))\n",
    "        \n",
    "        time.sleep(4)\n",
    "        \n",
    "        self.col_sensor_bp = self.blueprint_library.find(\"sensor.other.collision\")\n",
    "        \n",
    "        self.col_sensor = self.world.spawn_actor(self.col_sensor_bp, transform, attach_to=self.vehicle)\n",
    "        self.col_sensor.listen(lambda event: self.collision_data(event))\n",
    "        \n",
    "        while self.rgb_image is None:\n",
    "            time.sleep(0.01)\n",
    "            \n",
    "        self.episode_start_time = time.time()\n",
    "        \n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=0.0))\n",
    "        \n",
    "        return self.rgb_image\n",
    "    \n",
    "    def collision_data(self, event):\n",
    "        self.collision_hist.append(event)\n",
    "        \n",
    "    def process_img(self, image):\n",
    "        i = np.array(image.raw_data)\n",
    "        i2 = i.reshape((self.im_height, self.im_width, 4))\n",
    "        i3 = i2[:, :, :3]\n",
    "        self.rgb_image = i3.copy()\n",
    "        if self.SHOW_CAM:\n",
    "            self.disp_rgb_cam()\n",
    "            \n",
    "    def disp_rgb_cam(self):\n",
    "        cv2.imshow(\"Car front camera\" , self.rgb_image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            self.SHOW_CAM = False\n",
    "            \n",
    "    def step(self, action):\n",
    "        \n",
    "        if action == 0:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=0.8, steer=0.0))\n",
    "        if action == 1:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=0.8, steer=-1*self.STEER_AMT))\n",
    "        if action == 2:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=0.8, steer=1*self.STEER_AMT))\n",
    "        \n",
    "        v = self.vehicle.get_velocity()\n",
    "        v_kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "    \n",
    "        if len(self.collision_hist) != 0:\n",
    "            done = True\n",
    "            reward = -200\n",
    "        elif v_kmh < 50:\n",
    "            done = False\n",
    "            reward = -1\n",
    "        else:\n",
    "            done = False\n",
    "            reward = 1\n",
    "            \n",
    "        if time.time() > self.episode_start_time + SECONDS_PER_EPISODE:\n",
    "            done = True\n",
    "            \n",
    "        return self.rgb_image, reward, done, None\n",
    "    \n",
    "    def destroy_all_actors(self):\n",
    "        for actor in self.actor_list:\n",
    "            actor.destroy()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b76833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\n",
    "        \n",
    "        self.target_update_counter = 0\n",
    "        self.graph = tf.compat.v1.get_default_graph()\n",
    "        \n",
    "        ####check what these do\n",
    "        self.terminate = False\n",
    "        self.terminal_episode = False\n",
    "        self.training_initialized = False\n",
    "    \n",
    "    def create_model(self):\n",
    "        base_model = Xception(weights=None, include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3))\n",
    "        x= base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        predictions = Dense(3, activation='linear')(x)\n",
    "        \n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        model.run_eagerly = False\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def update_replay_memory(self, transition):\n",
    "        #transition = (current_state, action, reward, new_state, done)\n",
    "        self.replay_memory.append(transition)\n",
    "        \n",
    "    def train(self):\n",
    "        if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\n",
    "            return\n",
    "        \n",
    "        minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\n",
    "        \n",
    "        current_states = np.array([transition[0] for transition in minibatch])/255\n",
    "        #with self.graph.as_default():\n",
    "        current_qs_list = self.model.predict(current_states, PREDICTION_BATCH_SIZE)\n",
    "\n",
    "        new_states = np.array([transition[3] for transition in minibatch])/255\n",
    "        #with self.graph.as_default():\n",
    "        future_qs_list = self.target_model.predict(new_states, PREDICTION_BATCH_SIZE)\n",
    "        \n",
    "        X = []\n",
    "        Y = []\n",
    "        \n",
    "        for index, (current_state, action, reward, new_state, done) in enumerate(minibatch):\n",
    "            if not done:\n",
    "                max_future_q = np.max(future_qs_list[index])\n",
    "                new_q = reward + DISCOUNT * max_future_q\n",
    "            else:\n",
    "                new_q = reward\n",
    "            \n",
    "            current_qs = current_qs_list[index]\n",
    "            current_qs[action] = new_q\n",
    "\n",
    "            X.append(current_state)\n",
    "            Y.append(current_qs)\n",
    "        \n",
    "        #with self.graph.as_default():\n",
    "        self.model.fit(np.array(X)/255, np.array(Y), batch_size=TRAINING_BATCH_SIZE, verbose=0, shuffle=False)\n",
    "            \n",
    "        if self.terminal_episode:\n",
    "            self.target_update_counter += 1 \n",
    "        \n",
    "        if self.target_update_counter > UPDATE_TARGET_EVERY:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "            self.target_update_counter = 0\n",
    "        \n",
    "    def get_qs(self, state):\n",
    "        return self.model.predict(np.array(state).reshape(-1, *state.shape)/255)[0]\n",
    "        \n",
    "    def train_in_loop(self):\n",
    "        X = np.random.uniform(size=(1, IM_HEIGHT, IM_WIDTH, 3)).astype(np.float32)\n",
    "        Y = np.random.uniform(size=(1, 3)).astype(np.float32)\n",
    "        #with self.graph.as_default():\n",
    "        self.model.fit(X,Y, verbose=1, batch_size=1)\n",
    "\n",
    "        self.training_initialized = True\n",
    "\n",
    "        while True:\n",
    "            if self.terminate:\n",
    "                return\n",
    "            self.train()\n",
    "            time.sleep(0.01)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf7fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main section\n",
    "\n",
    "FPS = 60\n",
    "ep_rewards = [-200]\n",
    "average_rewards = []\n",
    "min_rewards = []\n",
    "max_rewards = []\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "#Memory segmentation\n",
    "# gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=MEMORY_FRACTION)\n",
    "# backend.set_session(tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)))\n",
    "\n",
    "# Create agent and environment\n",
    "env = CarEnv()\n",
    "agent = DQNAgent()\n",
    "#env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30efa28c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleeping....\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.1257 - accuracy: 0.0000e+00\n",
      "First predict start\n",
      "First predict over\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\carla\\lib\\site-packages\\ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c74b2448f44b50a1430d6e7792e379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?episodes/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1\n",
      "Episode: 2\n",
      "Episode: 3\n",
      "Episode: 4\n",
      "Episode: 5\n",
      "Simulation time: 1.3676429430643717 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\carla\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/One/network_data/final_episodes_5.model\\assets\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3f1e72a48ff2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[0mmax_rewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAGGREGATE_STATS_EVERY\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmax_rewards\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m \u001b[0mrewards_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"Episode Rewards\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mep_rewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Average Rewards\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0maverage_rewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Minimum Rewards\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmin_rewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Maximum Rewards\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax_rewards\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrewards_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\carla\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\carla\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         ]\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\carla\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\carla\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "# Start training thread and wait for training to be initialized\n",
    "trainer_thread = Thread(target=agent.train_in_loop, daemon=True)\n",
    "trainer_thread.start()\n",
    "print(\"sleeping....\")\n",
    "while not agent.training_initialized:\n",
    "    time.sleep(0.01)\n",
    "\n",
    "# X = np.random.uniform(size=(1, IM_HEIGHT, IM_WIDTH, 3)).astype(np.float32)\n",
    "# y = np.random.uniform(size=(1, 3)).astype(np.float32)\n",
    "# #with self.graph.as_default():\n",
    "# agent.model.fit(X,y, verbose=1, batch_size=1)\n",
    "    \n",
    "# Initialize predictions - forst prediction takes longer as of initialization that has to be done\n",
    "# It's better to do a first prediction then before we start iterating over episode steps\n",
    "print(\"First predict start\")\n",
    "agent.get_qs(np.ones((env.im_height, env.im_width, 3)))\n",
    "print(\"First predict over\")\n",
    "\n",
    "#Iterate over episodes\n",
    "start_time = time.time()\n",
    "for episode in tqdm_notebook(range(1, EPISODES + 1), ascii=True, unit=\"episodes\"):\n",
    "    \n",
    "    print(\"Episode: {}\".format(episode))\n",
    "    #Resetting episode reward and step number\n",
    "    episode_reward = 0\n",
    "    step = 1\n",
    "    \n",
    "    #reset environment and get initial state\n",
    "    \n",
    "    try:\n",
    "        current_state = env.reset()\n",
    "    except:\n",
    "        print(\"Error while resetting environment. Moving on to next episode.\")\n",
    "        env.destroy_all_actors()\n",
    "        continue\n",
    "    \n",
    "    #reset Flag and start iterating until episode ends\n",
    "    done = False\n",
    "    \n",
    "    #playing the episode\n",
    "    while True:\n",
    "        # This part stays mostly the same, the change is to query a model for Q values\n",
    "        if np.random.random() > epsilon:\n",
    "            # Get action from Q table\n",
    "            action = np.argmax(agent.get_qs(current_state))\n",
    "        else:\n",
    "            # Get random action\n",
    "            action = np.random.randint(0, 3)\n",
    "            # This takes no time, so we add a delay matching 60 FPS (prediction above takes longer)\n",
    "            time.sleep(1/FPS)\n",
    "            \n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        agent.terminal_episode = done\n",
    "        \n",
    "        # Transform new continous state to new discrete state and count reward\n",
    "        episode_reward += reward\n",
    "\n",
    "        # Every step we update replay memory\n",
    "        agent.update_replay_memory((current_state, action, reward, new_state, done))\n",
    "        #agent.train()\n",
    "\n",
    "        current_state = new_state\n",
    "        step += 1\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    # End of episode - destroy agents\n",
    "    env.destroy_all_actors()\n",
    "    \n",
    "    # Append episode reward to a list and log stats (every given number of episodes)\n",
    "    ep_rewards.append(episode_reward)\n",
    "    if episode > AGGREGATE_STATS_EVERY:\n",
    "        average_reward = sum(ep_rewards[-AGGREGATE_STATS_EVERY:])/len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        average_rewards.append(average_reward)\n",
    "        min_reward = min(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        min_rewards.append(min_reward)\n",
    "        max_reward = max(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        max_rewards.append(max_reward)\n",
    "        \n",
    "        #Save model if min reward is greater or equal to set value\n",
    "        if min_reward >= MIN_REWARD:\n",
    "            agent.model.save(\"Models/One/network_data/episodes_{}_min_reward_{}.model\".format(EPISODES, min_reward))\n",
    "    \n",
    "    if epsilon > MIN_EPSILON:\n",
    "        epsilon *= EPSILON_DECAY\n",
    "        epsilon = max(MIN_EPSILON, epsilon)\n",
    "\n",
    "agent.terminate = True\n",
    "trainer_thread.join()\n",
    "end_time = time.time()\n",
    "print(\"Simulation time: {} minutes\".format((end_time-start_time)/60))\n",
    "      \n",
    "agent.model.save(\"Models/One/network_data/final_episodes_{}.model\".format(EPISODES))\n",
    "\n",
    "average_rewards = [0]*(AGGREGATE_STATS_EVERY+1) + average_rewards\n",
    "min_rewards = [0]*(AGGREGATE_STATS_EVERY+1) + min_rewards\n",
    "max_rewards = [0]*(AGGREGATE_STATS_EVERY+1) + max_rewards        \n",
    "        \n",
    "rewards_df = pd.DataFrame({\"Episode Rewards\":ep_rewards, \"Average Rewards\":average_rewards, \"Minimum Rewards\":min_rewards, \"Maximum Rewards\": max_rewards})\n",
    "print(rewards_df)\n",
    "\n",
    "rewards_df.to_csv(\"Models/One/rewards/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144acf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_df = pd.read_csv(\"Models/One/rewards/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed297e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "rcParams[\"figure.figsize\"] = 10, 6\n",
    "plt.plot(rewards_df[\"Episode Rewards\"])\n",
    "plt.grid(True)\n",
    "plt.title(\"Episode Rewards\")\n",
    "plt.xlabel(\"episodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364e59f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "rcParams[\"figure.figsize\"] = 10, 6\n",
    "plt.plot(rewards_df[\"Average Rewards\"])\n",
    "plt.grid(True)\n",
    "plt.title(\"Average Rewards\")\n",
    "plt.xlabel(\"episodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a7712",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "rcParams[\"figure.figsize\"] = 10, 6\n",
    "plt.plot(rewards_df[\"Minimum Rewards\"])\n",
    "plt.grid(True)\n",
    "plt.title(\"Minimum Rewards\")\n",
    "plt.xlabel(\"episodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5dfb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "rcParams[\"figure.figsize\"] = 10, 6\n",
    "plt.plot(rewards_df[\"Maximum Rewards\"])\n",
    "plt.grid(True)\n",
    "plt.title(\"Maximum Rewards\")\n",
    "plt.xlabel(\"episodes\")\n",
    "#plt.ylim(-250, 50)\n",
    "#plt.yticks(list(range(-250,55,10)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69860e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "rcParams[\"figure.figsize\"] = 10, 6\n",
    "plt.plot(rewards_df[\"Episode Rewards\"], label='Episode Rewards')\n",
    "plt.plot(rewards_df[\"Average Rewards\"], label='Average Rewards')\n",
    "plt.plot(rewards_df[\"Minimum Rewards\"], label='Minimum Rewards')\n",
    "plt.plot(rewards_df[\"Maximum Rewards\"], label='Maximum Rewards')\n",
    "plt.grid(True)\n",
    "plt.title(\"Rewards\")\n",
    "plt.xlabel(\"episodes\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference model\n",
    "\n",
    "#Memory Fraction\n",
    "# gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=MEMORY_FRACTION)\n",
    "# backend.set_session(tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)))\n",
    "\n",
    "#load the model\n",
    "print(\"Start loading model...\")\n",
    "model = load_model(\"Models/One/network_data/final_episodes_1000.model\")\n",
    "print(\"Model loading complete.\")\n",
    "\n",
    "#create environment\n",
    "env = CarEnv()\n",
    "env.SHOW_CAM = False\n",
    "\n",
    "#For agent speed measurements - keeps last 60 frametimes\n",
    "fps_counter = deque(maxlen=60)\n",
    "\n",
    "# Initialize predictions - first prediction takes longer as of initialization that has to be done\n",
    "# It's better to do a first prediction then before we start iterating over episode steps\n",
    "model.predict(np.ones((1, env.im_height, env.im_width, 3)))\n",
    "\n",
    "SHOW_CAM = True\n",
    "NUM_EPISODES = 50\n",
    "\n",
    "#loop over episodes\n",
    "for episode in tqdm_notebook(range(NUM_EPISODES), ascii=True, unit=\"episodes\"):\n",
    "    \n",
    "    print(\"Restarting episode....\")\n",
    "    \n",
    "    #Reset environment and get initial state\n",
    "    current_state = env.reset()\n",
    "    env.collision_hist = []\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    #Loop over steps\n",
    "    while True:\n",
    "        \n",
    "        #For FPS counter\n",
    "        step_start = time.time()\n",
    "        \n",
    "        #Show current frame\n",
    "        if SHOW_CAM == True:\n",
    "            cv2.imshow(\"front camera\", current_state)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                SHOW_CAM = False\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "            \n",
    "            \n",
    "        #Predict an action based on current observation space\n",
    "        qs = model.predict(np.array(current_state).reshape(-1, *current_state.shape)/255)[0]\n",
    "        action = np.argmax(qs)\n",
    "        \n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        current_state = new_state\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "        # Measure step time, append to a deque, then print mean FPS for last 60 frames, q values and taken action\n",
    "        frame_time = time.time() - step_start\n",
    "        fps_counter.append(frame_time)\n",
    "        print(f'Agent: {len(fps_counter)/sum(fps_counter):>4.1f} FPS | Action: [{qs[0]:>5.2f}, {qs[1]:>5.2f}, {qs[2]:>5.2f}] {action}')\n",
    "        \n",
    "    #Destroy actors at the end of episode\n",
    "    env.destroy_all_actors()\n",
    "    \n",
    "cv2.destroyAllWindows()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7563e10d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c8585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a7cc07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d840ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b106a230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23284573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab276345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26beb04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a1c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf65383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472fc9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc17ec3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b62baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac083df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2a77b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951b084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e49564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6935ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6845e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b69462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef8733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3590fd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867a9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940be60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c169d659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeaab1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1652f690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa0231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e30bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37212fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.model.save(\"Models/One/network_data/episodes_{}_min_reward_{}.model\".format(EPISODES, min_reward))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b46766",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rewards = [0]*(AGGREGATE_STATS_EVERY+1) + average_rewards\n",
    "min_rewards = [0]*(AGGREGATE_STATS_EVERY+1) + min_rewards\n",
    "max_rewards = [0]*(AGGREGATE_STATS_EVERY+1) + max_rewards\n",
    "print(len(ep_rewards))\n",
    "print(len(average_rewards))\n",
    "print(len(min_rewards))\n",
    "print(len(max_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed761145",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rewards_df = pd.DataFrame({\"Episode Rewards\":ep_rewards, \"Average Rewards\":average_rewards, \"Minimum Rewards\":min_rewards, \"Maximum Rewards\": max_rewards})\n",
    "rewards_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779271a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_df.to_csv(\"Models/One/rewards/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf9fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Models/One/rewards/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316792e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df[\"Episode Rewards\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b6b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f97c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ep_rewards)\n",
    "plt.plot(average_rewards)\n",
    "plt.plot(min_rewards)\n",
    "plt.plot(max_rewards)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e323047",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.plot(ep_rewards)\n",
    "plt.plot(average_rewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e142d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.plot(df[\"Episode Rewards\"])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad04db20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 2.314\n",
    "type(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef607b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3fcdef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for actor in env.actor_list:\n",
    "    actor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.rgb_cam_sensor.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8855902",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_PREVIEW = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f739ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7256b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Append episode reward to a list and log stats (every given number of episodes)\n",
    "        ep_rewards.append(episode_reward)\n",
    "        if not episode % AGGREGATE_STATS_EVERY or episode == 1:\n",
    "            average_reward = sum(ep_rewards[-AGGREGATE_STATS_EVERY:])/len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "            min_reward = min(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "            max_reward = max(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "            agent.tensorboard.update_stats(reward_avg=average_reward, reward_min=min_reward, reward_max=max_reward, epsilon=epsilon)\n",
    "\n",
    "            # Save model, but only when min reward is greater or equal a set value\n",
    "            if min_reward >= MIN_REWARD:\n",
    "                agent.model.save(f'models/{MODEL_NAME}__{max_reward:_>7.2f}max_{average_reward:_>7.2f}avg_{min_reward:_>7.2f}min__{int(time.time())}.model')\n",
    "\n",
    "        # Decay epsilon\n",
    "        if epsilon > MIN_EPSILON:\n",
    "            epsilon *= EPSILON_DECAY\n",
    "            epsilon = max(MIN_EPSILON, epsilon)\n",
    "\n",
    "\n",
    "# Set termination flag for training thread and wait for it to finish\n",
    "agent.terminate = True\n",
    "trainer_thread.join()\n",
    "agent.model.save(f'models/{MODEL_NAME}__{max_reward:_>7.2f}max_{average_reward:_>7.2f}avg_{min_reward:_>7.2f}min__{int(time.time())}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37a395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a884f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3a7ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f644837d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be0bdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad1d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd13416b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfd8178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f8f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e632a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e08cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f581ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "state = np.array([[[2]]])\n",
    "np.reshape(-1, *state.shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312799a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bafa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning GPU memory to model\n",
    "#tf.config.gpu.set_per_process_memory_fraction(0.75)\n",
    "#tf.config.gpu.set_per_process_memory_growth(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5769df",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.compat.v1.reset_default_graph()\n",
    "graph = tf.compat.v1.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c177f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218f0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c6aab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aba9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48922216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffc81bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fcb58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0ce058",
   "metadata": {},
   "outputs": [],
   "source": [
    "    cv2.imshow(\"Car front camera\", image)\n",
    "    cv2.imshow(\"Perspective transform\", image_wraped)\n",
    "#     cv2.imshow(\"Binary image\", image_binary)\n",
    "#     cv2.imshow(\"Centroid\", image_gray)\n",
    "    cv2.imshow(\"Semantic Segmentation\", image_semantic)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text = 'average angle: ' + str(avg_angle_degrees) + '\\n' + 'steer: ' + str(steer)\n",
    "    image_semantic_binary = cv2.putText(image_semantic_binary, text, (10, 10), font, 0.3, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.imshow(\"Semantic Segmentation Binary\", image_semantic_wraped)\n",
    "    #cv2.imshow(\"Perspective transform semantic\", image_semantic_wraped)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):      #press 'q' to end the video feed\n",
    "        break\n",
    "\n",
    "print(image.shape)\n",
    "camera_sensor.stop()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41ebdd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae0b7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040925a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642305b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = 20\n",
    "b = 13\n",
    "\n",
    "c = tf.add(a, b, name=\"Add\")\n",
    "print(a)\n",
    "print(b)\n",
    "print(type(a), type(b))\n",
    "print(c)\n",
    "type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tf.multiply(c, a, name='Mul')\n",
    "e = tf.truediv(d, a, name=\"div\")\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b07582",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(20)\n",
    "b = tf.constant(13)\n",
    "c= a + b\n",
    "\n",
    "print(c)\n",
    "type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a4d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.compat.v1.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f167b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
